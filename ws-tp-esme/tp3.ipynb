{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Face recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Installation des dépendances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# executer cette cellule pour charger l'ensemble des fonctions/librairies utiles\n",
    "from IPython.core.display import HTML\n",
    "import requests\n",
    "#theme_url = \"https://raw.githubusercontent.com/ninjasoul/IPython_NB_Config/master/custom.css\"\n",
    "theme_url = \"https://raw.githubusercontent.com/ketch/HyperPython/master/custom.css\"\n",
    "rn = requests.get(theme_url)\n",
    "HTML(rn.text)\n",
    "from functools import partial\n",
    "import numpy as np\n",
    "import scipy.ndimage\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "%matplotlib notebook\n",
    "#%matplotlib inline\n",
    "import pip\n",
    "import imageio\n",
    "import skimage.morphology\n",
    "import skimage.segmentation\n",
    "import skimage.feature\n",
    "\n",
    "\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "plt.rcParams['image.interpolation'] = 'none'\n",
    "plt.rcParams['figure.max_open_warning'] = 100\n",
    "plt.rcParams['figure.figsize'] = 2, 2\n",
    "\n",
    "def format_coord(x, y, image):\n",
    "    x = int(x + 0.5)\n",
    "    y = int(y + 0.5)\n",
    "    try:\n",
    "        val = str(image[y, x])\n",
    "    except IndexError:\n",
    "        val = \"?\"\n",
    "    return \"color={} @ [{}, {}]\".format(val, y, x)\n",
    "\n",
    "def display_image_nb(image, title='', cmap=None):\n",
    "    fig, ax = plt.subplots(1,1)\n",
    "    if cmap is None:\n",
    "        ax.matshow(image)\n",
    "    else:\n",
    "        ax.matshow(image, cmap=cmap)\n",
    "    ax.set_xlabel(title)\n",
    "    ax.format_coord = partial(format_coord, image=image)\n",
    "    #return fig, ax\n",
    "\n",
    "def display_image_color(image, title=''):\n",
    "    fig, ax = plt.subplots(1,1)\n",
    "    ax.imshow(image)\n",
    "    ax.set_xlabel(title)\n",
    "    ax.format_coord = partial(format_coord, image=image)\n",
    "    #return fig, ax\n",
    "\n",
    "def draw_rectangle(y1, x1, y2, x2, color='red', ax=None, alpha=1):\n",
    "    \"\"\" Add a rectangle on an image \"\"\"\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    rect = mpatches.Rectangle((x1, y1), x2 - x1, y2 - y1,\n",
    "                              fill=False, edgecolor=color, linewidth=2, alpha=alpha)\n",
    "    ax.add_patch(rect)\n",
    "\n",
    "print(\"OK let's go\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Chargement des jeux de données\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Jeu de données de visages\n",
    "\n",
    "Nous utilisons le jeu de données **Labeled Faces in the Wild Home** (http://vis-www.cs.umass.edu/lfw/).\n",
    "\n",
    "La fonction fetch_lfw_people du package **sklearn.dataset** permet de télécharger facilement ce jeu de données (aide en ligne disponible ici: http://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_lfw_people.html)\n",
    "\n",
    "\n",
    "De façon à limiter le nombre d'images nous n'utiliserons que les visages pour lesquels nous disposons de plus de 20 images dans la base.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_lfw_people\n",
    "lfw_people = fetch_lfw_people(min_faces_per_person=20, slice_=(slice(69, 69+120), slice(78, 78+100)))\n",
    "dataset_face = lfw_people.images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Quelle est la dimension de chaque image ?\n",
    "- Combien d'images avez vous dans le tableau lfw_people ?\n",
    "- Affichez une image de la base\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(lfw_people.images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "affichez toutes les images contenant une photo de Bill Clinton (il y en a 29)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Jeu de données \"absence de visage\"\n",
    "\n",
    "Nous utilisons des images de type *background*, ne contenant pas de visage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous utilisons des images de type background, ne contenant pas de visage. Les images sont disponnibles ici: \n",
    "    \n",
    "https://www.dropbox.com/s/zhmv58rbcfu61q3/negative_image.tar.gz?dl=0\n",
    "\n",
    "Après avoir télécharger l'archive déplacer le tar.gz dans un repertoire accessible depuis votre image docker et utiliser le code suivant pour decompresser l'archive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chemin_vers_archive = '../negative_image.tar.gz'\n",
    "\n",
    "# décompressez l'archive, vous pouvez aussi utiliser un outil tels que winrar pour décompresser l'archive\n",
    "import tarfile\n",
    "tar_obj = tarfile.open(chemin_vers_archive)\n",
    "tar_obj.extractall('./')\n",
    "\n",
    "# vous devez des lors pouvoir acceder aux images dans ./negative_image/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De façon à obtenir des images de tailles comparables à celles des images de la base visages, nous prétraitons les images. Le code suivant découpe chaque image en sous-images de taille (62 x 47) et créé un tableau contenant toutes ses sous images.\n",
    "\n",
    "Nous ne gardons que 20000 images dans ce tableau."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "import glob\n",
    "\n",
    "max_i = 60\n",
    "max_j = 50\n",
    "negative_jpg_files = glob.glob('./negative_image/*.jpg')\n",
    "negative_dataset = []\n",
    "for image_file in negative_jpg_files:\n",
    "    data = imageio.imread(image_file)\n",
    "    tab = skimage.util.view_as_windows(data, (max_i, max_j), 100)\n",
    "    for i in range(tab.shape[0]):\n",
    "        for j in range(tab.shape[1]):\n",
    "            if len(negative_dataset) < 20000:\n",
    "                negative_dataset.append(tab[i,j])\n",
    "    if len(negative_dataset) > 20000:\n",
    "        break\n",
    "negative_dataset = np.array(negative_dataset)\n",
    "\n",
    "print(negative_dataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - afficher 5 images du tableau negative_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " De façon à avoir le même nombre d'image dans la base visages et dans la bases 'absence de visages' nous sélectionnons un sous ensemble des images de façon aléatoires dans le tableau negative_dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = np.random.choice(negative_dataset.shape[0], len(lfw_people.images))\n",
    "dataset_no_face = negative_dataset[indexes, :, :]\n",
    "display_image_nb(dataset_no_face[1000])\n",
    "print(dataset_no_face[1000].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_no_face.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Extraction de features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fonction compute_feature_vect permet d'extraire pour une image les histogrames des local binary pattern. Les différents histogrames sont concaténés dans un vecteur.\n",
    "\n",
    "<img src=\"http://srand.fr/lbp_histogram.png\">\n",
    "\n",
    "\n",
    "Lire le papier (section LBP): http://cs229.stanford.edu/proj2008/Jo-FaceDetectionUsingLBPfeatures.pdf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expliquez briévement ce qui est décrit dans le papier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.feature import local_binary_pattern\n",
    "def compute_feature_vect(image, debug=False):\n",
    "    radius = 2\n",
    "    n_points = 8 * radius\n",
    "    METHOD = 'uniform'\n",
    "    lbp = local_binary_pattern(image, n_points, radius, METHOD)\n",
    "    n_bins = 18\n",
    "    hists = []\n",
    "    if debug:\n",
    "        display_image_nb(image)\n",
    "    I = image.shape[0] // 6\n",
    "    J = image.shape[1] // 5\n",
    "    step = 10\n",
    "    tab = skimage.util.view_as_blocks(lbp, (I, J))\n",
    "    #tab = skimage.util.view_as_windows(lbp, (I,J), step=step)\n",
    "    c = 0\n",
    "    colors = ['blue', 'green', 'red']\n",
    "    for i in range(tab.shape[0]):\n",
    "        for j in range(tab.shape[1]):\n",
    "            c+=1\n",
    "            sub = tab[i, j]\n",
    "            hist, _ = np.histogram(sub, normed=True, bins=n_bins, range=(0, n_bins))\n",
    "            hists.append(hist.flatten())\n",
    "            if debug:\n",
    "                draw_rectangle(i*step, j*step, i*step+I-1, j*step+J-1, color=colors[c%len(colors)], alpha=0.8)\n",
    "    return np.array(hists).flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = compute_feature_vect(dataset_face[1000], debug=True)\n",
    "b = compute_feature_vect(dataset_no_face[1000], debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Apprentissage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans cette section nous utiliserons la librairie python sklearn, comme lors du tp2.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons créer une liste X de \"features\" associé à chaque image et une liste Y de labels associés à ses images.\n",
    "\n",
    "Pour chaque image du jeu de données dataset_face nous associeront le label 'face'\n",
    "Pour chaque image du jeu de données dataset_noface nous associeront le label 'noface'\n",
    "\n",
    "Créez ces deux listes (vous pouvez vous aidez de la fonction append ainsi que d'une boucle for)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# en utilisant une boucle for\n",
    "\n",
    "X = []\n",
    "Y = []\n",
    "for image in  `à remplacer`:\n",
    "    X.append(compute_feature_vect(image))\n",
    "    #Y.append('à remplacer')\n",
    "    Y.append()\n",
    "    \n",
    "for image in `à remplacer`:\n",
    "    X.append(compute_feature_vect(image))\n",
    "    Y.append('à remplacer')\n",
    "print(len(X))\n",
    "print(len(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Créez un classifieur de type k-nearest neighbors, avec k = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "clf = KNeighborsClassifier()\n",
    "\n",
    "# complétez ici:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilisez la fonction cross_val_score afin d'évaluer le taux de bonne reconnaissance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le code suivant permet de partitionner le jeu de donnée en un ensemble de test et un ensemble d'entrainement. \n",
    "Le classifieur est alors entrainé à reconnaitre chaque classe (visage vs. absence de visage) sur le jeu d'entrainement (méthode fit).\n",
    "\n",
    "Nous affichons ensuite le score obtenu sur le jeu de test, ainsi que la matrice de confusion associé.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, random_state=0, test_size=0.1)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "print(clf.score(X_test, y_test))\n",
    "\n",
    "prediction_on_testing_data = clf.predict(X_test)\n",
    "print(confusion_matrix(y_test, prediction_on_testing_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expliquez à quoi correspondent les nombres dans la matrices de confusions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrainez une nouvelle fois le classifieur mais cette fois en utilisant l'ensemble du jeu de donnée.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entrainez un second classifieur de type adaboost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "clf2 = # acompléter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expliquez en quelques phrases ce que vous avez fait jusqu'à présent dans ce tp, quels classifieur avez vous entrainez, comment, qu'est ce qu'ils permettent de faire, avec quelles performances etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Détection de visage "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fonction check_image vous permet de parcourir à l'aide d'une fenêtre glissante une image de test, et entoure en vert tous les visages détectés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def check_image(image_test, window_size = (60, 50), clf=clf):\n",
    "    STEP = max(window_size) //3\n",
    "    tab = skimage.util.view_as_windows(image_test, window_size, STEP)\n",
    "    display_image_nb(image_test)\n",
    "    for i in range(tab.shape[0]):\n",
    "        for j in range(tab.shape[1]):\n",
    "            block = tab[i, j]\n",
    "            features = compute_feature_vect(block)\n",
    "            prediction = clf.predict(features.flatten().reshape(1, -1))\n",
    "            #print(prediction)\n",
    "            if prediction == 'face':\n",
    "                draw_rectangle(i*STEP, j*STEP, i*STEP+window_size[0], j*STEP+window_size[1], color='green')\n",
    "\n",
    "            #if prediction != 'face':\n",
    "             #   draw_rectangle(i*STEP, j*STEP, i*STEP+window_size[0], j*STEP+window_size[1], color='red')\n",
    "                #display_image_nb(block)\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image_test = skimage.color.rgb2gray(imageio.imread(\"https://upload.wikimedia.org/wikipedia/commons/c/cb/ABBA_-_TopPop_1974_5.png\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "abba = skimage.transform.rescale(image_test, 0.9)\n",
    "check_image(abba)\n",
    "#check_image(abba, clf=clf2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img_test = \"https://cdn.mos.cms.futurecdn.net/nD3euWXQKyL2ufNAcEkSWY-970-80.jpg\"\n",
    "image = skimage.color.rgb2gray(imageio.imread(img_test))\n",
    "image = skimage.transform.rescale(image, 0.6)\n",
    "check_image(image, clf=clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testez la méthode sur 10 images (smartphone, ou sur le net). Pensez a utilisez la fonction rescale comme illustrez dans les exemples précédents, afin d'avoir une fenêtre d'analyse a peu près égale à la taille des visages présents dans l'image.\n",
    "\n",
    "Quelles sont les limites du système ?\n",
    "Que proposez vous pour y remédier ? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilisez Opencv pour détecter les visages\n",
    "\n",
    "La librairie OpenCV fourni un classifieur déjà entrainé pour détecter des visages et des yeux. \n",
    "suivez le tutoriel disponnible ici http://docs.opencv.org/trunk/d7/d8b/tutorial_py_face_detection.html pour utiliser cette detection sur les images précédentes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "import cv2\n",
    "# TODO: modify the path to the file\n",
    "face_cascade = cv2.CascadeClassifier(\"/root/anaconda3/share/OpenCV/haarcascades/haarcascade_frontalcatface_extended.xml\")\n",
    "eye_cascade = cv2.CascadeClassifier(\"/root/anaconda3/share/OpenCV/haarcascades/haarcascade_eye_tree_eyeglasses.xml\")\n",
    "\n",
    "# Complétez !\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
