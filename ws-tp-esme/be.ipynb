{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Noms et prénoms des membres du groupe:\n",
    "\n",
    "-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vision industrielle - TP noté"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exécuter la cellule suivante afin de charger l'ensemble des outils et fonctions nécessaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "from functools import partial\n",
    "import numpy as np\n",
    "import scipy.ndimage\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "%matplotlib notebook\n",
    "\n",
    "import imageio\n",
    "import skimage.morphology\n",
    "import skimage.segmentation\n",
    "import skimage.feature\n",
    "import skimage.data\n",
    "import cv2\n",
    "\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "plt.rcParams['image.interpolation'] = 'none'\n",
    "plt.rcParams['figure.max_open_warning'] = 100\n",
    "plt.rcParams['figure.figsize'] = 2, 2\n",
    "\n",
    "def format_coord(x, y, image):\n",
    "    x = int(x + 0.5)\n",
    "    y = int(y + 0.5)\n",
    "    try:\n",
    "        val = str(image[y, x])\n",
    "    except IndexError:\n",
    "        val = \"?\"\n",
    "    return \"color={} @ [{}, {}]\".format(val, y, x)\n",
    "\n",
    "def display_image_nb(image, title='', cmap=None):\n",
    "    fig, ax = plt.subplots(1,1)\n",
    "    if cmap is None:\n",
    "        ax.matshow(image)\n",
    "    else:\n",
    "        ax.matshow(image, cmap=cmap)\n",
    "    ax.set_xlabel(title)\n",
    "    ax.format_coord = partial(format_coord, image=image)\n",
    "    #return fig, ax\n",
    "\n",
    "def display_image_color(image, title=''):\n",
    "    fig, ax = plt.subplots(1,1)\n",
    "    ax.imshow(image)\n",
    "    ax.set_xlabel(title)\n",
    "    ax.format_coord = partial(format_coord, image=image)\n",
    "    #return fig, ax\n",
    "\n",
    "def display_image_color_opencv(image, title=''):\n",
    "    fig, ax = plt.subplots(1,1)\n",
    "    img = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    ax.imshow(img)\n",
    "    ax.set_xlabel(title)\n",
    "    ax.format_coord = partial(format_coord, image=image)\n",
    "    \n",
    "def draw_rectangle(y1, x1, y2, x2, color='red', ax=None, alpha=1):\n",
    "    \"\"\" Add a rectangle on an image \"\"\"\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    rect = mpatches.Rectangle((x1, y1), x2 - x1, y2 - y1,\n",
    "                              fill=False, edgecolor=color, linewidth=2, alpha=alpha)\n",
    "    ax.add_patch(rect)\n",
    "\n",
    "print(\"OK let's go\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercice 1: Trouver les différences\n",
    "\n",
    "Compléter le code suivant afin de trouver les différences entre les deux images img_nb_1, img_nb_2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chargement des images\n",
    "img_nb_1 = imageio.imread('./images/spot_diff_1.png')\n",
    "img_nb_2 = imageio.imread('./images/spot_diff_2.png')\n",
    "display_image_nb(img_nb_1, title='img1')\n",
    "display_image_nb(img_nb_2, title='img2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Calculer la différence entre **img_nb_1** et **img_nb_2**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_diff ="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Afficher l'image des différences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Calculer le masque binaire correspondant aux positions où une différence a été détectée (le masque doit valoir **True** là où une différence a été détectée)\n",
    "- Afficher ce masque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = \n",
    "\n",
    "# afficher le masque : \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Utiliser une opération morphologique afin de regrouper les régions du masque ayant des valeurs à True (i.e il s'agit ici d'enlever les trous dans les zones blanches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage.morphology\n",
    "\n",
    "new_mask = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afficher l'image original, et dessiner un rectange autour des zones dans lesquelles il y a eu une différence.\n",
    "\n",
    "Aide: le code est quasiment similaire à celui du tp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Combien de différences présentent les deux images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercice 2: Où est charlie ?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_image = cv2.imread(\"./images/waldo1.jpg\")\n",
    "display_image_color_opencv(scene_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_image = cv2.imread(\"./images/waldo_obj.png\")\n",
    "display_image_color_opencv(obj_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilisez les méthodes opencv suivante afin de trouver Charlie (i.e l'image obj_image) dans l'image scene_image:\n",
    "\n",
    "    - cv2.minMaxLoc (cf doc opencv)\n",
    "    - cv2.MatchTemplate (cf doc opencv + google)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilisez les méthodes suivantes afin de faire ressortir la partie de l'image contenant charlie que vous avez trouvé à la question précédente:\n",
    "\n",
    "    - cv2.addWeighted (cf doc opencv)\n",
    "    - les mask numpy (cf tp1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercice 3: Détection de véhicules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans cet exercice vous utiliserez des méthodes de machine learning afin de détecter la présence de véhicules dans des images.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Exemple de détection obtenu en faisant cet exercice: \n",
    "![alt text](./images/car_detected.png \"Car detected\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Téléchargement des données pour l'apprentissage\n",
    "\n",
    "Vous utiliserez les images disponnibles dans ./images/CarData/TrainImages et  ./images/CarData/TestImages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le fichier README.txt dans le répertoire CarData décrit le contenu de l'archive: \n",
    "\n",
    "[...]\n",
    "\n",
    "1. Training images\n",
    "These are located in CarData/TrainImages/. The positive (car) images are named pos-n.pgm (0 <= n <= 549). The negative (non-car) images are named similarly as neg-n.pgm (0 <= n <= 499).\n",
    "The training images are all 100x40 pixels in size.\n",
    "\n",
    "[...]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Afficher les 2 première images (une image negative et une image positive) de la base de donnée d'apprentissage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = imageio.imread('./images/CarData/TrainImages/pos-0.pgm')\n",
    "display_image_color(img1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Le code suivant permet d'ouvrir les différentes images (positives et négatives) et de les stocker dans des listes (images_positives et images_negatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "path = './images/CarData/TrainImages/'\n",
    "negative_files = glob.glob(path + 'neg-*.pgm')\n",
    "positive_files = glob.glob(path + 'pos-*.pgm')\n",
    "images_positives = [imageio.imread(positive_file) for positive_file in positive_files]\n",
    "images_negatives = [imageio.imread(negative_file) for negative_file in negative_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affichage de la première image positive\n",
    "display_image_nb(images_positives[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affichage de la 5 ème image negative\n",
    "display_image_nb(images_negatives[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- À quoi correspondent les images \"positives\" ? \n",
    "- À quoi correspondent les images \"negatives\" ? \n",
    "- Combien d'images avons nous dans chaque classe ?\n",
    "- Quelle est la taille de chaque image ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apprentissage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De façon à pré-traité les images, et à extraire un vecteur de caractéristiques décrivant le contenu de chaque image nous utiliserons la fonction suivante. Elle calcule des \"local_binary_pattern\" pour chaque image (comme vu lors du tp 3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.feature import local_binary_pattern\n",
    "\n",
    "def compute_feature_vect(image, debug=False):\n",
    "    radius = 2\n",
    "    n_points = 8 * radius\n",
    "    METHOD = 'uniform'\n",
    "    lbp = local_binary_pattern(image, n_points, radius, METHOD)\n",
    "    n_bins = 18\n",
    "    hists = []\n",
    "    if debug:\n",
    "        display_image_nb(image)\n",
    "    I = image.shape[0] / 6\n",
    "    J = image.shape[1] / 5\n",
    "    step = 10\n",
    "    #tab = skimage.util.view_as_blocks(lbp, (I, J))\n",
    "    tab = skimage.util.view_as_windows(lbp, (I,J), step=step)\n",
    "    c = 0\n",
    "    colors = ['blue', 'green', 'red']\n",
    "    for i in range(tab.shape[0]):\n",
    "        for j in range(tab.shape[1]):\n",
    "            c+=1\n",
    "            sub = tab[i, j]\n",
    "            hist, _ = np.histogram(sub, normed=True, bins=n_bins, range=(0, n_bins))\n",
    "            hists.append(hist.flatten())\n",
    "            if debug:\n",
    "                draw_rectangle(i*step, j*step, i*step+I-1, j*step+J-1, color=colors[c%len(colors)], alpha=0.8)\n",
    "    return np.array(hists).flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afin de pouvoir utiliser les outils d'apprentissages automatisés, les données doivent être mise au format suivant:\n",
    "\n",
    "    - X = data  (un vecteur avec tous les images pré-traités)\n",
    "    - Y = label (un vecteur avec les labels associés à chaque image)\n",
    "\n",
    "Nous utiliserons le label **\"negative\"** pour les images de la classe negative, et le label **\"positive\"** pour les images de la classe positive.\n",
    "\n",
    "\n",
    "**Compléter le code suivant:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "Y = []\n",
    "import random\n",
    "for image in images_negatives:\n",
    "    X.append(compute_feature_vect(image))\n",
    "    Y.append(    \"A\"   )\n",
    "    \n",
    "for image in images_positives:\n",
    "    X.append(compute_feature_vect(image))\n",
    "    Y.append(    \"B\"    )\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrainer un classifieur de type K-nearest neighbors (en utilisant 10 voisins).\n",
    "A l'aide de la fonction cross_val_score, calculer les pourcentages d'accuracy obtenus\n",
    "\n",
    "- Que pouvez vous dire sur ces pourcentages ? \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "\n",
    "\n",
    "clf_k_nearest_neighbors =  \n",
    "score_on_training_set = \n",
    "\n",
    "print(score_on_training_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Quel serait l'accuracy d'un classifieur aléatoire sur ce jeu de donnée ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utiliser un DummyClassifier pour vérifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "classifieur_tout_pourri = \n",
    "scores_cross_validation = \n",
    "print(scores_cross_validation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrainer un classifieur de type AdaBoost (en utilisant 200 estimateurs (n_estimators=200)).\n",
    "A l'aide de la fonction cross_val_score, calculer les pourcentages d'accuracy obtenus avec ce classifieur sur le jeu d'entrainement.\n",
    "\n",
    "Comparer ces résultats aux résultats obtenus avec le classifieur de type K-nearest neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "clf_adaboost = AdaBoostClassifier(                 )\n",
    "scores_cross_validation = \n",
    "print(scores_cross_validation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans la suite nous utiliserons le classifieur *clf_adaboost*.\n",
    "\n",
    "Lancer l'apprentissage pour ce classifieur (méthode fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_adaboost.fit(X,Y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconnaissance d'un véhicule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous diposons à présent d'un classifieur de type AdaBoost qui sait prédire la présence d'un véhicule dans une image de 40x100 pixels.\n",
    "\n",
    "Tester ce classifieur sur la première image posivite, et sur la 5 ème image negative.\n",
    "\n",
    "** N'oubliez pas d'utiliser la méthode compute_feature_vect afin de prétraiter les images **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_test1 = images_positives[0]\n",
    "display_image_nb(image_test1)\n",
    "prediction_image_test_1 = clf_adaboost.     # a completer        \n",
    "print(prediction_image_test_1)\n",
    "\n",
    "\n",
    "image_test2 = images_negatives[4]\n",
    "display_image_nb(image_test2)\n",
    "prediction_image_test_2 = clf_adaboost.     # a completer        \n",
    "print(prediction_image_test_2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Détection d'un véhicule dans une image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous nous interessons ici à la détection d'une véhicule dans une image plus grande que 40x100 pixels. Afin de détecter un véhicule nous utiliserons une fenêtre glissante comme vu lors du tp3. La fonction suivante vous permet d'utiliser une fenêtre glissante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_image(image_test, window_size = (40, 100), clf=None, compute_feat_function=None):\n",
    "    \"\"\"\n",
    "    image_test: image en entree\n",
    "    window_size: taille de la fenetre glissante (correspond a la taille des images dans l'ensemble d'apprentissage)\n",
    "    clf: votre classifieur deja entrainé\n",
    "    compute_feature_vect: la fonction de pré-traitement des images\n",
    "    \"\"\"\n",
    "    STEP = max(window_size) /5\n",
    "    tab = skimage.util.view_as_windows(image_test, window_size, STEP)\n",
    "    display_image_nb(image_test)\n",
    "    for i in range(tab.shape[0]):\n",
    "        for j in range(tab.shape[1]):\n",
    "            block = tab[i, j]\n",
    "            if compute_feat_function is not None:\n",
    "                block = compute_feat_function(block)\n",
    "            prediction = clf.predict(block.flatten())\n",
    "            #print(prediction)\n",
    "            if prediction == 'positive':\n",
    "                draw_rectangle(i*STEP, j*STEP, i*STEP+window_size[0], j*STEP+window_size[1], color='green')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple d'utilisation\n",
    "im1 = imageio.imread('./images/CarData/TestImages/test-43.pgm')\n",
    "display_image_nb(im1)\n",
    "#check_image(im1, window_size=(40, 100), clf=clf_adaboost, compute_feat_function=compute_feature_vect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testez le classifieur à l'aide de la méthode check_image sur 10 images du dossier CarData/TestImages/  (afficher les 10 résultats)\n",
    "\n",
    "Vous pouvez utiliser la méthode glob.glob ainsi qu'une boucle, ou utiliser le chemin complet vers les images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercice 4: Détection de chat\n",
    "\n",
    "Utiliser le détecteur d'opencv cv2.CascadeClassifier avec le jeux d'apprentissage /root/anaconda3/share/OpenCV/haarcascades/haarcascade_frontalcatface_extended.xml\n",
    "\n",
    "afin de détecter les chat dans l'image suivante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = imageio.imread('./images/cat3.jpg')\n",
    "display_image_color(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expliquez en vous basant sur ce que vous avez lors de ce cours comment ce détecteur a t'il été entrainé.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ecrivez le code necessaire afin de compter le nombre de chat présent dans une image, tester votre code sur quelques images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercice bonus:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En suivant les informations données [ici](https://fr.wikipedia.org/wiki/Filtre_de_Canny), réimplémenter le filtre de Canny.\n",
    "\n",
    "Comparez vos résultats avec le filtre de Canny disponnible dans skimage ainsi que celui disponnible dans opencv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fin\n",
    "\n",
    "Merci d'envoyer votre tp à Laurent.f.george@ gmail. com.\n",
    "\n",
    "(File->print_preview, puis enregistrer_sous)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
